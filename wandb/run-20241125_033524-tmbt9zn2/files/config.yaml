_wandb:
    value:
        cli_version: 0.18.7
        m: []
        python_version: 3.12.3
        t:
            "1":
                - 1
                - 11
                - 49
                - 55
            "2":
                - 1
                - 11
                - 49
                - 55
            "3":
                - 16
                - 23
                - 55
            "4": 3.12.3
            "5": 0.18.7
            "6": 4.46.1
            "8":
                - 5
            "12": 0.18.7
            "13": linux-x86_64
adam_epsilon:
    value: 1e-06
bert_lr:
    value: 3e-05
config_name:
    value: ""
data_dir:
    value: ./dataset/cdr
dev_file:
    value: dev_filter.data
down_dim:
    value: 512
evaluation_steps:
    value: -1
gnn_hidden_feat_dim:
    value: 256
gnn_num_layer:
    value: 4
gnn_num_node_type:
    value: 2
gradient_accumulation_steps:
    value: 1
learning_rate:
    value: 2e-05
load_path:
    value: ""
log_dir:
    value: logs/cdr/train_scibert-lr3e-5_accum1_unet-lr2e-5_bs2.log
max_grad_norm:
    value: 1
max_height:
    value: 42
max_seq_length:
    value: 1024
model_name_or_path:
    value: microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext
num_class:
    value: 2
num_labels:
    value: 1
num_train_epochs:
    value: 20
save_path:
    value: checkpoints/cdr/train_scibert-lr3e-5_accum1_unet-lr2e-5_bs2.pt
seed:
    value: 666
test_batch_size:
    value: 2
test_file:
    value: test_filter.data
tokenizer_name:
    value: ""
train_batch_size:
    value: 2
train_file:
    value: train_filter.data
transformer_type:
    value: bert
unet_in_dim:
    value: 768
unet_out_dim:
    value: 768
use_graph:
    value: true
use_unet:
    value: false
wandb_project_name:
    value: thesis-local
warmup_ratio:
    value: 0.06
